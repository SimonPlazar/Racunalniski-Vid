{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:36:47.034526Z",
     "start_time": "2025-11-12T12:36:33.897237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ],
   "id": "7324b9abfa64a763",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:36:48.788068Z",
     "start_time": "2025-11-12T12:36:47.068558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Models import HomographyRegressor, HomographyClassifier\n",
    "from Models import HomographyPairDataset, FixedSrcRandomDispDataset\n",
    "\n",
    "from Models import save_checkpoint, load_latest_checkpoint\n",
    "from Models import offsets_to_class_indices, classes_to_offsets\n",
    "from Models import classification_loss\n",
    "\n",
    "from Generator import get_images_from_names, get_random_images, get_all_images"
   ],
   "id": "4c51f835af5056ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:36:49.187319Z",
     "start_time": "2025-11-12T12:36:49.148200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def nn_train_regressor(model, num_epochs, batch_size, samples_per_epoch, model_file_name,\n",
    "                       images, optimizer, criterion,\n",
    "                       checkpoint_dir=\"checkpoints\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    device = next(model.parameters()).device\n",
    "    start_epoch = load_latest_checkpoint(checkpoint_dir, model, optimizer, device)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"runs\"))\n",
    "\n",
    "    dataset = HomographyPairDataset(images, samples_per_epoch)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True,\n",
    "                            num_workers=0, pin_memory=True)\n",
    "\n",
    "    epoch_pbar = tqdm(\n",
    "        range(start_epoch, num_epochs),\n",
    "        desc=\"Training\",\n",
    "        ncols=120,\n",
    "        miniters=1,\n",
    "        smoothing=0,\n",
    "        dynamic_ncols=True,\n",
    "        initial=start_epoch,\n",
    "        total=num_epochs\n",
    "    )\n",
    "    try:\n",
    "        for epoch in epoch_pbar:\n",
    "            model.train()\n",
    "            epoch_loss, epoch_mae, epoch_rmse = 0.0, 0.0, 0.0\n",
    "\n",
    "            for pairs, offsets in dataloader:\n",
    "                pairs = pairs.to(device)\n",
    "                offsets = offsets.to(device)\n",
    "\n",
    "                preds = model(pairs)\n",
    "\n",
    "                # === Compute loss ===\n",
    "                loss = criterion(preds, offsets)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # === Metrics ===\n",
    "                with torch.no_grad():\n",
    "                    mae = torch.mean(torch.abs(preds - offsets)).item()\n",
    "                    rmse = torch.sqrt(torch.mean((preds - offsets) ** 2) + 1e-8).item()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_mae += mae\n",
    "                epoch_rmse += rmse\n",
    "\n",
    "            # === Epoch summary ===\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            avg_mae = epoch_mae / len(dataloader)\n",
    "            avg_rmse = epoch_rmse / len(dataloader)\n",
    "\n",
    "            epoch_pbar.set_postfix({\n",
    "                \"loss\": f\"{avg_loss:.4f}\",\n",
    "                \"mae\": f\"{avg_mae:.3f}px\",\n",
    "                \"rmse\": f\"{avg_rmse:.3f}px\"\n",
    "            })\n",
    "\n",
    "            writer.add_scalar(\"Loss/MSE\", avg_loss, epoch)\n",
    "            writer.add_scalar(\"Error/MAE\", avg_mae, epoch)\n",
    "            writer.add_scalar(\"Error/RMSE\", avg_rmse, epoch)\n",
    "\n",
    "            # === Checkpoint every N epochs ===\n",
    "            if (epoch + 1) % 1000 == 0 or (epoch + 1) == num_epochs:\n",
    "                save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "\n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(f\"‚úÖ Final model saved: {model_file_name}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        epoch_pbar.close()\n",
    "        print(f\"\\n‚ö†Ô∏è Interrupted at epoch {epoch + 1}\")\n",
    "        save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "        print(\"‚úÖ Checkpoint saved\")\n",
    "\n",
    "    finally:\n",
    "        epoch_pbar.close()\n",
    "        writer.close()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ],
   "id": "c9eb9032a42626ea",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:36:49.249247Z",
     "start_time": "2025-11-12T12:36:49.210343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nn_train_classify(model, dataloader, num_epochs, model_file_name, optimizer, criterion,\n",
    "                      checkpoint_dir=\"checkpoints\", num_classes=21, disp_range=(-16, 16)):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    device = next(model.parameters()).device\n",
    "    start_epoch = load_latest_checkpoint(checkpoint_dir, model, optimizer, device)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"runs\"))\n",
    "\n",
    "    epoch_pbar = tqdm(\n",
    "        range(start_epoch, num_epochs),\n",
    "        desc=\"Training\",\n",
    "        ncols=120,\n",
    "        miniters=1,\n",
    "        smoothing=0,\n",
    "        dynamic_ncols=True,\n",
    "        initial=start_epoch,\n",
    "        total=num_epochs\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for epoch in epoch_pbar:\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_rmse_hard = 0.0\n",
    "            running_rmse_soft = 0.0\n",
    "            count = 0\n",
    "\n",
    "            for pairs, offsets in dataloader:\n",
    "                pairs = pairs.to(device)\n",
    "                offsets = offsets.to(device)\n",
    "                B = pairs.shape[0]\n",
    "\n",
    "                # --- Forward ---\n",
    "                logits = model(pairs)  # (B, 8, 21)\n",
    "\n",
    "                # --- Compute loss ---\n",
    "                loss = classification_loss(criterion, logits, offsets,\n",
    "                                           disp_range=disp_range, num_classes=num_classes)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --- Metrics ---\n",
    "                with torch.no_grad():\n",
    "                    pred_hard = classes_to_offsets(logits, disp_range, soft=False)\n",
    "                    pred_soft = classes_to_offsets(logits, disp_range, soft=True)\n",
    "\n",
    "                    # rmse_hard_val = rmse(pred_hard, offsets).mean().item()\n",
    "                    # rmse_soft_val = rmse(pred_soft, offsets).mean().item()\n",
    "                    # rmse_hard_val = torch.sqrt(((pred_hard - offsets) ** 2).mean(dim=-1)).item()\n",
    "                    # rmse_soft_val = torch.sqrt(((pred_soft - offsets) ** 2).mean(dim=-1)).item()\n",
    "                    per_rmse_hard = torch.sqrt(((pred_hard - offsets) ** 2).mean(dim=-1) + 1e-8)\n",
    "                    per_rmse_soft = torch.sqrt(((pred_soft - offsets) ** 2).mean(dim=-1) + 1e-8)\n",
    "\n",
    "                # --- Logging ---\n",
    "                running_loss += loss.item() * B\n",
    "                running_rmse_hard += per_rmse_hard.sum().item()\n",
    "                running_rmse_soft += per_rmse_soft.sum().item()\n",
    "                count += B\n",
    "\n",
    "            # Average metrics per epoch\n",
    "            avg_loss = running_loss / count\n",
    "            avg_rmse_hard = running_rmse_hard / count\n",
    "            avg_rmse_soft = running_rmse_soft / count\n",
    "\n",
    "            epoch_pbar.set_postfix({\n",
    "                \"loss\": f\"{avg_loss:.4f}\",\n",
    "                \"rmse_hard\": f\"{avg_rmse_hard:.3f}px\",\n",
    "                \"rmse_soft\": f\"{avg_rmse_soft:.3f}px\"\n",
    "            })\n",
    "\n",
    "            # TensorBoard\n",
    "            writer.add_scalar(\"Loss/train\", avg_loss, epoch + 1)\n",
    "            writer.add_scalar(\"RMSE/hard\", avg_rmse_hard, epoch + 1)\n",
    "            writer.add_scalar(\"RMSE/soft\", avg_rmse_soft, epoch + 1)\n",
    "\n",
    "            # --- Checkpoint every N epochs ---\n",
    "            if (epoch + 1) % 1000 == 0 or (epoch + 1) == num_epochs:\n",
    "                save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "\n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(f\"‚úÖ Final model saved: {model_file_name}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        epoch_pbar.close()\n",
    "        print(f\"\\n‚ö†Ô∏è Interrupted at epoch {epoch + 1}\")\n",
    "        save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "        print(\"‚úÖ Checkpoint saved\")\n",
    "\n",
    "    finally:\n",
    "        epoch_pbar.close()\n",
    "        writer.close()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ],
   "id": "ce930f1906db4b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:47:03.025218Z",
     "start_time": "2025-11-12T12:44:01.195296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # TRAIN Regressor\n",
    "#\n",
    "# PREPROCESSED_DIR = \"datasets/val2017_preprocessed\"\n",
    "# num_epochs = 30000\n",
    "# batch_size = 32\n",
    "# learning_rate = 1e-4\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "#\n",
    "# model = HomographyRegressor(dropout_rate=0.1).to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "#\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#\n",
    "# image_names = [\n",
    "#     \"000000002299.jpg\",\n",
    "#     #     # \"000000000285.jpg\",\n",
    "#     #     # \"000000000632.jpg\",\n",
    "# ]\n",
    "# images = get_images_from_names(image_names, PREPROCESSED_DIR)\n",
    "# # images = get_random_images(1, image_dir=PREPROCESSED_DIR)\n",
    "# # images = get_all_images(PREPROCESSED_DIR)\n",
    "#\n",
    "# print(f\"üì∑ Loaded {len(images)} image(s) for training\")\n",
    "#\n",
    "# nn_train_regressor(\n",
    "#     model=model,\n",
    "#     num_epochs=num_epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     samples_per_epoch=64,\n",
    "#     model_file_name=f\"h_regressor_test.pth\",\n",
    "#     images=images,\n",
    "#     optimizer=optimizer,\n",
    "#     criterion=criterion,\n",
    "#     checkpoint_dir=\"checkpoints_homography_regressor_test\"\n",
    "# )"
   ],
   "id": "3e65e0d1d7f93b81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "üì∑ Loaded 1 image(s) for training\n",
      "üöÄ Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 200/30000 [02:58<7:22:31,  1.12it/s, loss=38.5699, mae=4.894px, rmse=6.198px]Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    self._run()\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 775, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Users\\simon\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'checkpoints_homography_regressor_test\\\\runs\\\\events.out.tfevents.1762951441.TRISTAN-Laptop.38096.1'\n",
      "Training:   1%|          | 200/30000 [02:59<7:24:36,  1.12it/s, loss=45.1973, mae=5.273px, rmse=6.713px]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'checkpoints_homography_regressor_test\\\\runs\\\\events.out.tfevents.1762951441.TRISTAN-Laptop.38096.1'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# images = get_random_images(1, image_dir=PREPROCESSED_DIR)\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# images = get_all_images(PREPROCESSED_DIR)\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33müì∑ Loaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(images)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m image(s) for training\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[43mnn_train_regressor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m    \u001B[49m\u001B[43msamples_per_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_file_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mh_regressor_test.pth\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m=\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcheckpoints_homography_regressor_test\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m     36\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 81\u001B[39m, in \u001B[36mnn_train_regressor\u001B[39m\u001B[34m(model, num_epochs, batch_size, samples_per_epoch, model_file_name, images, optimizer, criterion, checkpoint_dir)\u001B[39m\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m     80\u001B[39m     epoch_pbar.close()\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m     \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     82\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available():\n\u001B[32m     83\u001B[39m         torch.cuda.empty_cache()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:1200\u001B[39m, in \u001B[36mSummaryWriter.close\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1198\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m  \u001B[38;5;66;03m# ignore double close\u001B[39;00m\n\u001B[32m   1199\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m writer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.all_writers.values():\n\u001B[32m-> \u001B[39m\u001B[32m1200\u001B[39m     \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1201\u001B[39m     writer.close()\n\u001B[32m   1202\u001B[39m \u001B[38;5;28mself\u001B[39m.file_writer = \u001B[38;5;28mself\u001B[39m.all_writers = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:153\u001B[39m, in \u001B[36mFileWriter.flush\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    147\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mflush\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    148\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Flushes the event file to disk.\u001B[39;00m\n\u001B[32m    149\u001B[39m \n\u001B[32m    150\u001B[39m \u001B[33;03m    Call this method to make sure that all pending events have been written to\u001B[39;00m\n\u001B[32m    151\u001B[39m \u001B[33;03m    disk.\u001B[39;00m\n\u001B[32m    152\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevent_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:125\u001B[39m, in \u001B[36mEventFileWriter.flush\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    119\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mflush\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    120\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Flushes the event file to disk.\u001B[39;00m\n\u001B[32m    121\u001B[39m \n\u001B[32m    122\u001B[39m \u001B[33;03m    Call this method to make sure that all pending events have been\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[33;03m    written to disk.\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_async_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:186\u001B[39m, in \u001B[36m_AsyncWriter.flush\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    181\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Write all the enqueued bytestring before this flush call to disk.\u001B[39;00m\n\u001B[32m    182\u001B[39m \n\u001B[32m    183\u001B[39m \u001B[33;03mBlock until all the above bytestring are written.\u001B[39;00m\n\u001B[32m    184\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    185\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n\u001B[32m--> \u001B[39m\u001B[32m186\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_check_worker_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._closed:\n\u001B[32m    188\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mWriter is closed\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:212\u001B[39m, in \u001B[36m_AsyncWriter._check_worker_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    210\u001B[39m exception = \u001B[38;5;28mself\u001B[39m._worker.exception\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m212\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 61\u001B[39m, in \u001B[36mnn_train_regressor\u001B[39m\u001B[34m(model, num_epochs, batch_size, samples_per_epoch, model_file_name, images, optimizer, criterion, checkpoint_dir)\u001B[39m\n\u001B[32m     53\u001B[39m avg_rmse = epoch_rmse / \u001B[38;5;28mlen\u001B[39m(dataloader)\n\u001B[32m     55\u001B[39m epoch_pbar.set_postfix({\n\u001B[32m     56\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m     57\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmae\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_mae\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33mpx\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     58\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrmse\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_rmse\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33mpx\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     59\u001B[39m })\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_scalar\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mLoss/MSE\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mavg_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     62\u001B[39m writer.add_scalar(\u001B[33m\"\u001B[39m\u001B[33mError/MAE\u001B[39m\u001B[33m\"\u001B[39m, avg_mae, epoch)\n\u001B[32m     63\u001B[39m writer.add_scalar(\u001B[33m\"\u001B[39m\u001B[33mError/RMSE\u001B[39m\u001B[33m\"\u001B[39m, avg_rmse, epoch)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:381\u001B[39m, in \u001B[36mSummaryWriter.add_scalar\u001B[39m\u001B[34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001B[39m\n\u001B[32m    376\u001B[39m torch._C._log_api_usage_once(\u001B[33m\"\u001B[39m\u001B[33mtensorboard.logging.add_scalar\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    378\u001B[39m summary = scalar(\n\u001B[32m    379\u001B[39m     tag, scalar_value, new_style=new_style, double_precision=double_precision\n\u001B[32m    380\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m381\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_file_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_summary\u001B[49m\u001B[43m(\u001B[49m\u001B[43msummary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mglobal_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwalltime\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:115\u001B[39m, in \u001B[36mFileWriter.add_summary\u001B[39m\u001B[34m(self, summary, global_step, walltime)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Add a `Summary` protocol buffer to the event file.\u001B[39;00m\n\u001B[32m    103\u001B[39m \n\u001B[32m    104\u001B[39m \u001B[33;03mThis method wraps the provided summary in an `Event` protocol buffer\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    112\u001B[39m \u001B[33;03m    walltime (from time.time()) seconds after epoch\u001B[39;00m\n\u001B[32m    113\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    114\u001B[39m event = event_pb2.Event(summary=summary)\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mglobal_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwalltime\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:99\u001B[39m, in \u001B[36mFileWriter.add_event\u001B[39m\u001B[34m(self, event, step, walltime)\u001B[39m\n\u001B[32m     95\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     96\u001B[39m     \u001B[38;5;66;03m# Make sure step is converted from numpy or other formats\u001B[39;00m\n\u001B[32m     97\u001B[39m     \u001B[38;5;66;03m# since protobuf might not convert depending on version\u001B[39;00m\n\u001B[32m     98\u001B[39m     event.step = \u001B[38;5;28mint\u001B[39m(step)\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevent_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:117\u001B[39m, in \u001B[36mEventFileWriter.add_event\u001B[39m\u001B[34m(self, event)\u001B[39m\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, event_pb2.Event):\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    114\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mExpected an event_pb2.Event proto, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    115\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m but got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % \u001B[38;5;28mtype\u001B[39m(event)\n\u001B[32m    116\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_async_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSerializeToString\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:171\u001B[39m, in \u001B[36m_AsyncWriter.write\u001B[39m\u001B[34m(self, bytestring)\u001B[39m\n\u001B[32m    166\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Enqueue the given bytes to be written asychronously.\"\"\"\u001B[39;00m\n\u001B[32m    167\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n\u001B[32m    168\u001B[39m     \u001B[38;5;66;03m# Status of the worker should be checked under the lock to avoid\u001B[39;00m\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# multiple threads passing the check and then switching just before\u001B[39;00m\n\u001B[32m    170\u001B[39m     \u001B[38;5;66;03m# blocking on putting to the queue which might result in a deadlock.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_check_worker_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    172\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._closed:\n\u001B[32m    173\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mWriter is closed\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:212\u001B[39m, in \u001B[36m_AsyncWriter._check_worker_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    210\u001B[39m exception = \u001B[38;5;28mself\u001B[39m._worker.exception\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m212\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1045\u001B[39m, in \u001B[36mThread._bootstrap_inner\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1042\u001B[39m     _sys.setprofile(_profile_hook)\n\u001B[32m   1044\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1045\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m   1047\u001B[39m     \u001B[38;5;28mself\u001B[39m._invoke_excepthook(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:244\u001B[39m, in \u001B[36m_AsyncWriterThread.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    243\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m244\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    245\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ex:\n\u001B[32m    246\u001B[39m         \u001B[38;5;28mself\u001B[39m.exception = ex\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:275\u001B[39m, in \u001B[36m_AsyncWriterThread._run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    273\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mself\u001B[39m._shutdown_signal:\n\u001B[32m    274\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_record_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    276\u001B[39m     \u001B[38;5;28mself\u001B[39m._has_pending_data = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    277\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m queue.Empty:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py:40\u001B[39m, in \u001B[36mRecordWriter.write\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m     38\u001B[39m header_crc = struct.pack(\u001B[33m\"\u001B[39m\u001B[33m<I\u001B[39m\u001B[33m\"\u001B[39m, masked_crc32c(header))\n\u001B[32m     39\u001B[39m footer_crc = struct.pack(\u001B[33m\"\u001B[39m\u001B[33m<I\u001B[39m\u001B[33m\"\u001B[39m, masked_crc32c(data))\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_writer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheader\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader_crc\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mfooter_crc\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:775\u001B[39m, in \u001B[36mGFile.write\u001B[39m\u001B[34m(self, file_content)\u001B[39m\n\u001B[32m    771\u001B[39m         \u001B[38;5;28mself\u001B[39m.write_started = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    773\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    774\u001B[39m         \u001B[38;5;66;03m# append the later chunks\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m775\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_content\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbinary_mode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    776\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    777\u001B[39m     \u001B[38;5;66;03m# add to temp file, but wait for flush to write to final filesystem\u001B[39;00m\n\u001B[32m    778\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.write_temp \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:167\u001B[39m, in \u001B[36mLocalFileSystem.append\u001B[39m\u001B[34m(self, filename, file_content, binary_mode)\u001B[39m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mappend\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename, file_content, binary_mode=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    160\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Append string file contents to a file.\u001B[39;00m\n\u001B[32m    161\u001B[39m \n\u001B[32m    162\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    165\u001B[39m \u001B[33;03m        binary_mode: bool, write as binary if True, otherwise text\u001B[39;00m\n\u001B[32m    166\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_content\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mab\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbinary_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43ma\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:171\u001B[39m, in \u001B[36mLocalFileSystem._write\u001B[39m\u001B[34m(self, filename, file_content, mode)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_write\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename, file_content, mode):\n\u001B[32m    170\u001B[39m     encoding = \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mutf8\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m io.open(filename, mode, encoding=encoding) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    172\u001B[39m         compatify = compat.as_bytes \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;28;01melse\u001B[39;00m compat.as_text\n\u001B[32m    173\u001B[39m         f.write(compatify(file_content))\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: b'checkpoints_homography_regressor_test\\\\runs\\\\events.out.tfevents.1762951441.TRISTAN-Laptop.38096.1'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T12:42:02.027814Z",
     "start_time": "2025-11-12T12:36:49.597572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # TRAIN Classifier\n",
    "#\n",
    "# PREPROCESSED_DIR = \"datasets/val2017_preprocessed\"\n",
    "# num_epochs = 30000\n",
    "# samples_per_epoch = 64\n",
    "# batch_size = 32\n",
    "# learning_rate = 1e-4\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "#\n",
    "# # model = HomographyRegressor(dropout_rate=0.1).to(device)\n",
    "# # criterion = nn.MSELoss()\n",
    "# model = HomographyClassifier(num_classes=21, class_dim=8, dropout_rate=0.1).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# # optimizer = optim.Adam(model.parameters())\n",
    "#\n",
    "# image_names = [\n",
    "#     \"000000002299.jpg\",\n",
    "#     #     # \"000000000285.jpg\",\n",
    "#     #     # \"000000000632.jpg\",\n",
    "# ]\n",
    "# images = get_images_from_names(image_names, PREPROCESSED_DIR)\n",
    "# # images = get_random_images(image_dir=PREPROCESSED_DIR, num_images=16)\n",
    "# # images = get_all_images(image_dir=PREPROCESSED_DIR)\n",
    "#\n",
    "# print(f\"üì∑ Loaded {len(images)} image(s) for training\")\n",
    "#\n",
    "# dataset = HomographyPairDataset(images, samples_per_epoch=samples_per_epoch)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "#\n",
    "# # from Generator import get_corners\n",
    "# # Create dataset with fixed src\n",
    "# # dataset = FixedSrcRandomDispDataset(\n",
    "# #     image=images[0],\n",
    "# #     src_corners=get_corners(32, 32, 64),\n",
    "# #     samples_per_epoch=samples_per_epoch,\n",
    "# #     disp_range=(-16, 16)\n",
    "# # )\n",
    "# # dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "#\n",
    "# nn_train_classify(\n",
    "#     model=model,\n",
    "#     dataloader=dataloader,\n",
    "#     num_epochs=num_epochs,\n",
    "#     model_file_name=f\"h_classify_test.pth\",\n",
    "#     optimizer=optimizer,\n",
    "#     criterion=criterion,\n",
    "#     checkpoint_dir=\"checkpoints_homography_classify_test\"\n",
    "# )"
   ],
   "id": "de3c465a6575f0c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "üì∑ Loaded 1 image(s) for training\n",
      "üöÄ Starting training from scratch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 324/30000 [04:45<7:16:04,  1.13it/s, loss=2.7513, rmse_hard=8.505px, rmse_soft=6.854px] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Interrupted at epoch 325\n",
      "‚úÖ Checkpoint saved\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
