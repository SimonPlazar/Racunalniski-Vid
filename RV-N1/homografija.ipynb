{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T19:37:57.770762Z",
     "start_time": "2025-11-08T19:37:57.754901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ],
   "id": "7324b9abfa64a763",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T19:37:57.874812Z",
     "start_time": "2025-11-08T19:37:57.851361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Models import HomographyRegressor, HomographyClassifier\n",
    "from Models import save_checkpoint, load_latest_checkpoint\n",
    "from Models import offsets_to_class_indices, classes_to_offsets\n",
    "from Models import HomographyPairDataset, FixedSrcRandomDispDataset\n",
    "from Models import classification_loss, rmse"
   ],
   "id": "4c51f835af5056ff",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T19:37:57.976759Z",
     "start_time": "2025-11-08T19:37:57.922196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nn_train_multi(model, dataloader, num_epochs, model_file_name, optimizer, criterion,\n",
    "                   checkpoint_dir=\"checkpoints\", num_classes=21, disp_range=(-16, 16)):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    device = next(model.parameters()).device\n",
    "    start_epoch = load_latest_checkpoint(checkpoint_dir, model, optimizer, device)\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"runs\"))\n",
    "\n",
    "    epoch_pbar = tqdm(\n",
    "        range(start_epoch, num_epochs),\n",
    "        desc=\"Training\",\n",
    "        ncols=120,\n",
    "        miniters=1,\n",
    "        smoothing=0,\n",
    "        dynamic_ncols=True,\n",
    "        initial=start_epoch,\n",
    "        total=num_epochs\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for epoch in epoch_pbar:\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_rmse_hard = 0.0\n",
    "            running_rmse_soft = 0.0\n",
    "            count = 0\n",
    "\n",
    "            for pairs, offsets in dataloader:\n",
    "                pairs = pairs.to(device)\n",
    "                offsets = offsets.to(device)\n",
    "                B = pairs.shape[0]\n",
    "\n",
    "                # --- Forward ---\n",
    "                logits = model(pairs)  # (B, 8, 21)\n",
    "\n",
    "                # --- Compute loss ---\n",
    "                loss = classification_loss(criterion, logits, offsets,\n",
    "                                           disp_range=disp_range, num_classes=num_classes)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # --- Metrics ---\n",
    "                with torch.no_grad():\n",
    "                    pred_hard = classes_to_offsets(logits, disp_range, soft=False)\n",
    "                    pred_soft = classes_to_offsets(logits, disp_range, soft=True)\n",
    "\n",
    "                    rmse_hard_val = rmse(pred_hard, offsets).mean().item()\n",
    "                    rmse_soft_val = rmse(pred_soft, offsets).mean().item()\n",
    "\n",
    "                # --- Logging ---\n",
    "                running_loss += loss.item() * B\n",
    "                running_rmse_hard += rmse_hard_val * B\n",
    "                running_rmse_soft += rmse_soft_val * B\n",
    "                count += B\n",
    "\n",
    "            # Average metrics per epoch\n",
    "            avg_loss = running_loss / count\n",
    "            avg_rmse_hard = running_rmse_hard / count\n",
    "            avg_rmse_soft = running_rmse_soft / count\n",
    "\n",
    "            epoch_pbar.set_postfix({\n",
    "                \"loss\": f\"{avg_loss:.4f}\",\n",
    "                \"rmse_hard\": f\"{avg_rmse_hard:.3f}px\",\n",
    "                \"rmse_soft\": f\"{avg_rmse_soft:.3f}px\"\n",
    "            })\n",
    "\n",
    "            # TensorBoard\n",
    "            writer.add_scalar(\"Loss/train\", avg_loss, epoch + 1)\n",
    "            writer.add_scalar(\"RMSE/hard\", avg_rmse_hard, epoch + 1)\n",
    "            writer.add_scalar(\"RMSE/soft\", avg_rmse_soft, epoch + 1)\n",
    "\n",
    "            # --- Checkpoint every N epochs ---\n",
    "            if (epoch + 1) % 1000 == 0 or (epoch + 1) == num_epochs:\n",
    "                save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "\n",
    "        # Save final model\n",
    "        torch.save(model.state_dict(), model_file_name)\n",
    "        print(f\"‚úÖ Final model saved: {model_file_name}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        epoch_pbar.close()\n",
    "        print(f\"\\n‚ö†Ô∏è Interrupted at epoch {epoch + 1}\")\n",
    "        save_checkpoint(checkpoint_dir, epoch + 1, model, optimizer)\n",
    "        print(\"‚úÖ Checkpoint saved\")\n",
    "\n",
    "    finally:\n",
    "        epoch_pbar.close()\n",
    "        writer.close()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n"
   ],
   "id": "a84fb34901631e1a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-08T19:50:39.482162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAIN\n",
    "\n",
    "from Generator import get_images_from_names, get_random_images, get_all_images\n",
    "\n",
    "PREPROCESSED_DIR = \"datasets/val2017_preprocessed\"\n",
    "num_epochs = 30000\n",
    "samples_per_epoch = 128\n",
    "batch_size = 128\n",
    "# learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# model = HomographyRegressor(dropout_rate=0.1).to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "model = HomographyClassifier(num_classes=21, class_dim=8, dropout_rate=0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# image_names = [\n",
    "#     \"000000002299.jpg\",\n",
    "#     #     # \"000000000285.jpg\",\n",
    "#     #     # \"000000000632.jpg\",\n",
    "# ]\n",
    "# images = get_images_from_names(image_names, PREPROCESSED_DIR)\n",
    "# images = get_random_images(image_dir=PREPROCESSED_DIR, num_images=16)\n",
    "images = get_all_images(image_dir=PREPROCESSED_DIR)\n",
    "\n",
    "print(f\"üì∑ Loaded {len(images)} image(s) for training\")\n",
    "\n",
    "dataset = HomographyPairDataset(images, samples_per_epoch=samples_per_epoch)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "\n",
    "# from Generator import get_corners\n",
    "# Create dataset with fixed src\n",
    "# dataset = FixedSrcRandomDispDataset(\n",
    "#     image=images[0],\n",
    "#     src_corners=get_corners(32, 32, 64),\n",
    "#     samples_per_epoch=samples_per_epoch,\n",
    "#     disp_range=(-16, 16)\n",
    "# )\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "\n",
    "nn_train_multi(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=num_epochs,\n",
    "    model_file_name=f\"h_classify.pth\",\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    checkpoint_dir=\"checkpoints_homography_classify\"\n",
    ")"
   ],
   "id": "ce4a8c3e1540c313",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T19:39:38.470298Z",
     "start_time": "2025-11-08T19:39:38.454110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # visualization of classification results\n",
    "#\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = HomographyClassifier(num_classes=21, class_dim=8).to(device)\n",
    "# state = torch.load(\"checkpoints_homography_class_multi/checkpoint_epoch_5000.pth\")[\"model_state_dict\"]\n",
    "# # state = torch.load(\"checkpoints_homography_clasify_oneImage/h_clasify_ep50000_I1.pth\")\n",
    "# model.load_state_dict(state)\n",
    "# model.eval()\n",
    "#\n",
    "# img = cv2.imread(\"datasets/val2017_preprocessed/000000002299.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# visualize_classification_result(model, img, soft_decode=False)\n",
    "# # visualize_classification_result_dataloader(\n",
    "# #     model=model,\n",
    "# #     dataloader=dataloader,\n",
    "# #     num_samples=3,\n",
    "# #     soft_decode=True,\n",
    "# #     device=device\n",
    "# # )"
   ],
   "id": "2060805e186d8ab3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T19:39:38.498380Z",
     "start_time": "2025-11-08T19:39:38.488439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from Models import test_offset_class_conversion\n",
    "#\n",
    "# test_offset_class_conversion()"
   ],
   "id": "a2813ad42dc6c87c",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
