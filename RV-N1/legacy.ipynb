{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_train_multi(model, num_epochs, batch_size, samples_per_epoch, model_file_name, images,\n",
    "                   optimizer, criterion, checkpoint_dir=\"checkpoints\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Resume from checkpoint\n",
    "    checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")])\n",
    "    checkpoints = sorted(checkpoints, key=extract_epoch)\n",
    "    if checkpoints:\n",
    "        latest_ckpt = os.path.join(checkpoint_dir, checkpoints[-1])\n",
    "        checkpoint = torch.load(latest_ckpt, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "        print(f\"‚úÖ Resuming from checkpoint: {latest_ckpt} (epoch {start_epoch})\")\n",
    "    else:\n",
    "        print(\"üöÄ Starting training from scratch.\")\n",
    "\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"runs\"))\n",
    "\n",
    "    dataset = HomographyPairDataset(images, samples_per_epoch)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=0, pin_memory=True)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mae = 0.0\n",
    "\n",
    "        # Progress bar for batches within epoch\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", ncols=120, leave=False)\n",
    "\n",
    "        for batch_pairs, batch_offsets in progress_bar:\n",
    "            batch_pairs = batch_pairs.to(device)\n",
    "            batch_offsets = batch_offsets.to(device)\n",
    "\n",
    "            # Forward\n",
    "            preds = model(batch_pairs)\n",
    "            loss = criterion(preds, -batch_offsets)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            batch_loss = loss.item()\n",
    "            epoch_loss += batch_loss\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mae = torch.mean(torch.abs(preds - (-batch_offsets))).item()\n",
    "                epoch_mae += mae\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=f\"{batch_loss:.6f}\", mae=f\"{mae:.4f}\")\n",
    "\n",
    "        # Average metrics for the epoch\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        avg_mae = epoch_mae / len(dataloader)\n",
    "        avg_rmse = np.sqrt(avg_loss)\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar(\"Loss/RMSE\", avg_rmse, epoch)\n",
    "        writer.add_scalar(\"Error/MAE\", avg_mae, epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 100 == 0 or (epoch + 1) == num_epochs:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pth\")\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            # Keep only last 4 checkpoints\n",
    "            checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")])\n",
    "            checkpoints = sorted(checkpoints, key=extract_epoch)\n",
    "            while len(checkpoints) > 4:\n",
    "                old_ckpt = os.path.join(checkpoint_dir, checkpoints[0])\n",
    "                os.remove(old_ckpt)\n",
    "                checkpoints.pop(0)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), model_file_name)\n",
    "    print(f\"‚úÖ Final model saved: {model_file_name}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def nn_train_single(model, num_epochs, model_file_name, img, optimizer, criterion, checkpoint_dir=\"checkpoints\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    start_epoch = 0\n",
    "\n",
    "    # üîÑ Resume if checkpoint exists\n",
    "    checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")])\n",
    "    checkpoints = sorted(checkpoints, key=extract_epoch)\n",
    "    if checkpoints:\n",
    "        latest_ckpt = os.path.join(checkpoint_dir, checkpoints[-1])\n",
    "        checkpoint = torch.load(latest_ckpt, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"]\n",
    "        print(f\"‚úÖ Resuming from checkpoint: {latest_ckpt} (epoch {start_epoch})\")\n",
    "    else:\n",
    "        print(\"üöÄ Starting training from scratch.\")\n",
    "\n",
    "    # ‚úÖ TensorBoard logger\n",
    "    writer = SummaryWriter(log_dir=os.path.join(checkpoint_dir, \"runs\"))\n",
    "\n",
    "    # üîÅ Training loop with progress bar for epochs\n",
    "    progress_bar = tqdm(range(start_epoch, num_epochs), desc=\"Training\", ncols=100)\n",
    "\n",
    "    # pair, offsets, *_ = generate_pair(\n",
    "    #     img=random.choice(img) if isinstance(img, list) else img,\n",
    "    #     window_size=64,\n",
    "    #     margin=16,\n",
    "    #     disp_range=(-16, 16)\n",
    "    # )\n",
    "    # pair = torch.from_numpy(pair).permute(2, 0, 1).unsqueeze(0).to(device).float()  # 1x2x64x64\n",
    "    # offsets = torch.from_numpy(offsets.flatten()).unsqueeze(0).to(device).float()  # 1x8\n",
    "\n",
    "    for epoch in progress_bar:\n",
    "        model.train()\n",
    "\n",
    "        pair, offsets, *_ = generate_pair(\n",
    "            img=random.choice(img) if isinstance(img, list) else img,\n",
    "            window_size=64,\n",
    "            margin=16,\n",
    "            disp_range=(-16, 16)\n",
    "        )\n",
    "\n",
    "        pair = torch.from_numpy(pair).permute(2, 0, 1).unsqueeze(0).to(device).float()  # 1x2x64x64\n",
    "        offsets = torch.from_numpy(offsets.flatten()).unsqueeze(0).to(device).float()  # 1x8\n",
    "\n",
    "        # Forward\n",
    "        preds = model(pair)\n",
    "        loss = criterion(preds, -offsets)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # üîπ Log loss to TensorBoard\n",
    "        rmse = torch.sqrt(loss + 1e-8)\n",
    "        writer.add_scalar(\"Loss/RMSE\", rmse.item(), epoch)\n",
    "        with torch.no_grad():\n",
    "            mae = torch.mean(torch.abs(preds - -offsets))\n",
    "        writer.add_scalar(\"Error/MAE\", mae.item(), epoch)\n",
    "\n",
    "        # Update progress bar with current epoch and loss\n",
    "        progress_bar.set_description(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.6f}\")\n",
    "\n",
    "        # üíæ Save checkpoint every 1000 epochs\n",
    "        if (epoch + 1) % 1000 == 0 or (epoch + 1) == num_epochs:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch + 1}.pth\")\n",
    "            torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "            # print(f\"\\nüíæ Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "            # üßπ Keep only last 4 checkpoints\n",
    "            checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")])\n",
    "            checkpoints = sorted(checkpoints, key=extract_epoch)\n",
    "            while len(checkpoints) > 4:\n",
    "                old_ckpt = os.path.join(checkpoint_dir, checkpoints[0])\n",
    "                os.remove(old_ckpt)\n",
    "                # print(f\"üóëÔ∏è Removed old checkpoint: {old_ckpt}\")\n",
    "                checkpoints.pop(0)\n",
    "\n",
    "    writer.close()\n",
    "    progress_bar.close()\n",
    "\n",
    "    # ‚úÖ Save final model\n",
    "    torch.save(model.state_dict(), model_file_name)\n",
    "    print(f\"‚úÖ Final model saved: {model_file_name}\")\n",
    "\n",
    "    # üßπ Clear GPU cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"üßπ GPU memory cleared. Current allocated: {torch.cuda.memory_allocated(device) / 1e9:.2f} GB\")\n",
    "\n",
    "\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1e9\n",
    "        reserved = torch.cuda.memory_reserved(device) / 1e9\n",
    "        total = torch.cuda.get_device_properties(device).total_memory / 1e9\n",
    "        print(f\"GPU Memory Status:\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} GB\")\n",
    "        print(f\"  Total:     {total:.2f} GB\")\n",
    "        print(f\"  Free:      {total - reserved:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA not available\")\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"‚úÖ GPU cache cleared\")\n",
    "        check_gpu_memory()\n",
    "    else:\n",
    "        print(\"CUDA not available\")"
   ],
   "id": "dfcd87e990a91259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # TRAIN REGRESSOR\n",
    "#\n",
    "# num_epochs = 30000\n",
    "# batch_size = 32\n",
    "# learning_rate = 1e-4\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "#\n",
    "# model = HomographyRegressor(dropout_rate=0.1).to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#\n",
    "# # image_names = [\n",
    "# #     \"000000002299.jpg\",\n",
    "# #     # \"000000000285.jpg\",\n",
    "# #     # \"000000000632.jpg\",\n",
    "# # ]\n",
    "# # images = get_images_from_names(image_names, PREPROCESSED_DIR)\n",
    "# images = get_random_images(image_dir=PREPROCESSED_DIR)\n",
    "# print(f\"üì∑ Loaded {len(images)} image(s) for training\")\n",
    "#\n",
    "# # nn_train_single(\n",
    "# #     model=model,\n",
    "# #     num_epochs=num_epochs,\n",
    "# #     model_file_name=f\"h_regressor_ep{num_epochs}_I{len(images)}.pth\",\n",
    "# #     img=images[0] if len(images) == 1 else images,\n",
    "# #     optimizer=optimizer,\n",
    "# #     criterion=criterion,\n",
    "# #     checkpoint_dir=\"checkpoints_homography_regressor_oneImage\"\n",
    "# # )\n",
    "#\n",
    "# nn_train_multi(\n",
    "#     model=model,\n",
    "#     num_epochs=num_epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     samples_per_epoch=64,\n",
    "#     model_file_name=f\"h_regressor_multi.pth\",\n",
    "#     images=images,\n",
    "#     optimizer=optimizer,\n",
    "#     criterion=criterion,\n",
    "#     checkpoint_dir=\"checkpoints_homography_regressor_multi\"\n",
    "# )"
   ],
   "id": "442906171ce0e8dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------\n",
    "# EVALUACIJSKI MODUL\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "# --- 1) Generiranje testnega nabora (~100 slik √ó 10 primerov) ---\n",
    "def generate_test_set(images, n_images=100, samples_per_image=10,\n",
    "                      window_size=64, margin=16, disp_range=(-16, 16), seed=42):\n",
    "    \"\"\"\n",
    "    images: lista numpy sivinskih slik\n",
    "    n_images: koliko razliƒçnih izvornih slik izbrati (max len(images))\n",
    "    samples_per_image: ≈°tevilo primerov na sliko\n",
    "    returns: lista sample dictov:\n",
    "      {\n",
    "        'image': full_image,\n",
    "        'pair': pair (2chan 64x64 float32),\n",
    "        'offsets': gt_offsets (4x2 float32),\n",
    "        'src_corners': src_corners (4x2),\n",
    "        'dst_corners': dst_corners (4x2),\n",
    "        'x': x, 'y': y,\n",
    "        'orig_patch': orig_patch,\n",
    "        'warped_patch': warped_patch\n",
    "      }\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    selected = images[:min(n_images, len(images))]\n",
    "    samples = []\n",
    "    for img in selected:\n",
    "        for _ in range(samples_per_image):\n",
    "            pair, offsets, src_corners, warped_full = generate_pair(img, window_size=window_size, margin=margin,\n",
    "                                                                    disp_range=disp_range)\n",
    "            dst_corners = src_corners + offsets\n",
    "            # Find x,y from src_corners (top-left)\n",
    "            x = int(src_corners[0, 0]);\n",
    "            y = int(src_corners[0, 1])\n",
    "            orig_patch = (img[y:y + window_size, x:x + window_size]).astype(np.uint8)\n",
    "            warped_patch = (warped_full[y:y + window_size, x:x + window_size]).astype(np.uint8)\n",
    "            samples.append({\n",
    "                'image': img,\n",
    "                'pair': pair,  # float32 [H,W,2] / normalized [0,1]\n",
    "                'offsets': offsets.reshape(4, 2),\n",
    "                'src_corners': src_corners,\n",
    "                'dst_corners': dst_corners,\n",
    "                'x': x, 'y': y,\n",
    "                'orig_patch': orig_patch,\n",
    "                'warped_patch': warped_patch\n",
    "            })\n",
    "    print(f\"‚û°Ô∏è Generiranih {len(samples)} testnih primerov iz {len(selected)} slik.\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "# --- 2) RMSE utility ---\n",
    "def corner_rmse(pred_offsets, gt_offsets):\n",
    "    \"\"\"\n",
    "    pred_offsets, gt_offsets: (4,2) arrays\n",
    "    return scalar RMSE over 8 values\n",
    "    \"\"\"\n",
    "    diff = (pred_offsets - gt_offsets).astype(np.float32).reshape(-1)\n",
    "    return float(np.sqrt(np.mean(diff ** 2) + 1e-12))\n",
    "\n",
    "\n",
    "# --- 3) Eval: Nevronski model (regresor ali klasifikator) ---\n",
    "def eval_model_on_testset(model, test_samples, device,\n",
    "                          model_type='regressor',  # 'regressor' or 'classifier'\n",
    "                          disp_range=(-16, 16), negate_pred=False,\n",
    "                          soft_decode=False, batch_size=32):\n",
    "    \"\"\"\n",
    "    model_type: 'regressor' -> model returns (B,8) offsets; 'classifier' -> logits (B,num_classes,8)\n",
    "    negate_pred: if your regressor predicts negative offsets during training, set True\n",
    "    soft_decode: if classifier, whether to soft-decode expected value\n",
    "    returns: dict with 'rmses' list, 'per_sample' list of dicts with preds etc.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {'rmses': [], 'per_sample': []}\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_samples), batch_size):\n",
    "            batch = test_samples[i:i + batch_size]\n",
    "            pairs = np.stack([s['pair'] for s in batch], axis=0)  # (B,H,W,2)\n",
    "            pairs_t = torch.from_numpy(pairs).permute(0, 3, 1, 2).float().to(device)  # (B,2,H,W)\n",
    "            preds = model(pairs_t)\n",
    "            if model_type == 'classifier':\n",
    "                # preds shape (B, num_classes, 8)\n",
    "                pred_offsets = classes_to_offsets(preds, disp_range, soft=soft_decode).cpu().numpy()  # (B,8)\n",
    "            else:\n",
    "                pred_offsets = preds.cpu().numpy()  # (B,8)\n",
    "                if negate_pred:\n",
    "                    pred_offsets = -pred_offsets\n",
    "            # reshape Bx8 -> Bx4x2\n",
    "            pred_offsets = pred_offsets.reshape(pred_offsets.shape[0], 4, 2)\n",
    "            for j, s in enumerate(batch):\n",
    "                rmse = corner_rmse(pred_offsets[j], s['offsets'])\n",
    "                results['rmses'].append(rmse)\n",
    "                results['per_sample'].append({\n",
    "                    'pred_offsets': pred_offsets[j],\n",
    "                    'gt_offsets': s['offsets'],\n",
    "                    'src_corners': s['src_corners'],\n",
    "                    'dst_corners_gt': s['dst_corners'],\n",
    "                    'orig_patch': s['orig_patch'],\n",
    "                    'warped_patch': s['warped_patch'],\n",
    "                    'image': s['image'],\n",
    "                    'x': s['x'], 'y': s['y'],\n",
    "                    'rmse': rmse\n",
    "                })\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- 4) Klasiƒçni OpenCV pristop (SIFT/SURF/ORB + findHomography) ---\n",
    "def estimate_homography_classical(orig_patch, warped_patch, min_matches=4):\n",
    "    \"\"\"\n",
    "    SIFT-only homography estimator.\n",
    "    Returns: (success:bool, H:ndarray|None, num_matches:int, message:str)\n",
    "    \"\"\"\n",
    "    assert orig_patch.ndim == 2 and warped_patch.ndim == 2\n",
    "\n",
    "    # create SIFT detector\n",
    "    try:\n",
    "        sift = cv2.SIFT_create()\n",
    "    except Exception as e:\n",
    "        return False, None, 0, f\"SIFT not available: {e}\"\n",
    "\n",
    "    # detect and compute\n",
    "    kp1, des1 = sift.detectAndCompute(orig_patch, None)\n",
    "    kp2, des2 = sift.detectAndCompute(warped_patch, None)\n",
    "\n",
    "    if des1 is None or des2 is None or len(kp1) < 2 or len(kp2) < 2:\n",
    "        return False, None, 0, f\"Not enough keypoints ({len(kp1) if kp1 else 0}, {len(kp2) if kp2 else 0})\"\n",
    "\n",
    "    # FLANN matcher for SIFT\n",
    "    index_params = dict(algorithm=1, trees=5)  # KDTree\n",
    "    search_params = dict(checks=50)\n",
    "    matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    try:\n",
    "        knn_matches = matcher.knnMatch(des1, des2, k=2)\n",
    "    except Exception as e:\n",
    "        return False, None, 0, f\"FLANN matching failed: {e}\"\n",
    "\n",
    "    # Lowe's ratio test\n",
    "    good = []\n",
    "    for m in knn_matches:\n",
    "        if len(m) == 2:\n",
    "            a, b = m\n",
    "            if a.distance < 0.75 * b.distance:\n",
    "                good.append(a)\n",
    "\n",
    "    if len(good) < min_matches:\n",
    "        return False, None, len(good), f\"Too few good matches ({len(good)})\"\n",
    "\n",
    "    # build point arrays and estimate homography\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    try:\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    except Exception as e:\n",
    "        return False, None, len(good), f\"findHomography failed: {e}\"\n",
    "\n",
    "    if H is None:\n",
    "        return False, None, len(good), \"findHomography returned None\"\n",
    "\n",
    "    inliers = int(mask.sum()) if mask is not None else 0\n",
    "    return True, H, len(good), f\"SIFT: success, inliers={inliers}\"\n",
    "\n",
    "\n",
    "def eval_classical_on_testset(test_samples, fallback_identity=True,\n",
    "                              use_256_for_classical=False):\n",
    "    \"\"\"\n",
    "    Evaluate classical approach on list of test_samples (as generated).\n",
    "    If use_256_for_classical: will upsample patches to 256x256 before detection (to help classical),\n",
    "      then the computed corner error is rescaled (divided by 4) as requested.\n",
    "    Returns results dict similar to eval_model_on_testset plus num_failures count.\n",
    "    \"\"\"\n",
    "    results = {'rmses': [], 'per_sample': [], 'num_failures': 0, 'num_total': len(test_samples)}\n",
    "    for s in test_samples:\n",
    "        orig = s['orig_patch']\n",
    "        warped = s['warped_patch']\n",
    "        # optionally upsample to 256x256:\n",
    "        scale_factor = 1\n",
    "        if use_256_for_classical:\n",
    "            target = 256\n",
    "            scale_factor = target / orig.shape[0]\n",
    "            orig_up = cv2.resize(orig, (target, target), interpolation=cv2.INTER_LINEAR)\n",
    "            warped_up = cv2.resize(warped, (target, target), interpolation=cv2.INTER_LINEAR)\n",
    "            ok, H, nm, msg = estimate_homography_classical(orig_up, warped_up)\n",
    "            if ok:\n",
    "                # we computed H that maps src->dst in upsampled coordinates.\n",
    "                # To apply on original coordinates, adjust H for scaling:\n",
    "                S = np.array([[1 / scale_factor, 0, 0], [0, 1 / scale_factor, 0], [0, 0, 1]])\n",
    "                H_adj = S @ H @ np.linalg.inv(S)\n",
    "                H_used = H_adj\n",
    "            else:\n",
    "                H_used = None\n",
    "        else:\n",
    "            ok, H, nm, msg = estimate_homography_classical(orig, warped)\n",
    "            H_used = H if ok else None\n",
    "\n",
    "        if H_used is None and fallback_identity:\n",
    "            # identity homography => predicted dst corners = src_corners\n",
    "            pred_dst = s['src_corners']\n",
    "            results['num_failures'] += 1\n",
    "            comment = 'fallback_identity'\n",
    "        elif H_used is None:\n",
    "            pred_dst = s['src_corners']\n",
    "            comment = 'failed_no_fallback'\n",
    "            results['num_failures'] += 1\n",
    "        else:\n",
    "            # apply H to src_corners (each point as homogenous)\n",
    "            pts = s['src_corners'].reshape(-1, 2)\n",
    "            ones = np.ones((pts.shape[0], 1))\n",
    "            hom_pts = np.concatenate([pts, ones], axis=1).T  # 3x4\n",
    "            mapped = (H_used @ hom_pts).T  # 4x3\n",
    "            mapped = mapped[:, :2] / mapped[:, 2:3]\n",
    "            pred_dst = mapped.astype(np.float32)\n",
    "            comment = f\"ok_matches={nm}\"\n",
    "\n",
    "        pred_offsets = pred_dst - s['src_corners']\n",
    "        rmse = corner_rmse(pred_offsets, s['offsets'])\n",
    "        # adjust RMSE if we used 256-upsample and user requested dividing by 4\n",
    "        if use_256_for_classical:\n",
    "            rmse = float(rmse / 4.0)\n",
    "\n",
    "        results['rmses'].append(rmse)\n",
    "        results['per_sample'].append({\n",
    "            'pred_offsets': pred_offsets,\n",
    "            'gt_offsets': s['offsets'],\n",
    "            'src_corners': s['src_corners'],\n",
    "            'dst_corners_gt': s['dst_corners'],\n",
    "            'rmse': rmse,\n",
    "            'comment': comment\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- 5) Plotting and statistics ---\n",
    "def summarize_and_plot(\n",
    "        results_dict,\n",
    "        labels,\n",
    "        outdir='eval_results',\n",
    "        bins=40,\n",
    "        save_plots=True,\n",
    "        ymax=200\n",
    "):\n",
    "    \"\"\"\n",
    "    results_dict: list of results (each has 'rmses')\n",
    "    labels: list of labels\n",
    "    ymax: y-axis limit for boxplot + histogram (None = auto)\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    rmse_arrays = [np.array(r['rmses'], dtype=np.float32) for r in results_dict]\n",
    "\n",
    "    # ---- SUMMARY PRINT ----\n",
    "    summary = {}\n",
    "    for lab, arr, r in zip(labels, rmse_arrays, results_dict):\n",
    "        mean = float(np.mean(arr))\n",
    "        med = float(np.median(arr))\n",
    "        std = float(np.std(arr))\n",
    "        num = len(arr)\n",
    "        num_fail = r.get('num_failures', 0)\n",
    "        summary[lab] = {'mean': mean, 'median': med, 'std': std, 'n': num, 'failures': num_fail}\n",
    "        print(f\"--- {lab} --- n={num}, failures={num_fail}\\n  mean={mean:.3f}, median={med:.3f}, std={std:.3f}\")\n",
    "\n",
    "    # ---- BOXPLOT ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    # plt.boxplot(rmse_arrays, labels=labels, showfliers=True)\n",
    "    plt.boxplot(rmse_arrays, tick_labels=labels, showfliers=True)\n",
    "\n",
    "    if ymax is not None:\n",
    "        plt.ylim(0, ymax)\n",
    "\n",
    "    plt.ylabel(\"RMSE (px)\")\n",
    "    plt.title(\"RMSE boxplot\")\n",
    "    if save_plots:\n",
    "        p = os.path.join(outdir, \"rmse_boxplot.png\")\n",
    "        plt.savefig(p, dpi=150)\n",
    "        print(\"‚û°Ô∏è Shrani:\", p)\n",
    "    plt.show()\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# EXAMPLE uporabe (po treningu)\n",
    "# -------------------------\n",
    "# Predpostavke:\n",
    "# - ima≈° nalo≈æen model (regressor ali classifier) kot 'model' v device\n",
    "# - ima≈° seznam sivinskih slik 'images' (npr. get_random_images(...))\n",
    "# - ƒçe uporablja≈° classifier, nastavi model_type='classifier' pri eval_model_on_testset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HomographyRegressor().to(device)\n",
    "# state = torch.load(\"checkpoints_homography_regressor_oneImage/checkpoint_epoch_50000.pth\")[\"model_state_dict\"]\n",
    "state = torch.load(\"checkpoints_homography_regressor_oneImage/h_regressor_ep50000_I1.pth\")\n",
    "model.load_state_dict(state)\n",
    "\n",
    "# Primer: generiraj testset\n",
    "test_samples = generate_test_set(\n",
    "    images=get_random_images(\n",
    "        num_images=100,\n",
    "        image_dir=PREPROCESSED_DIR\n",
    "    ),\n",
    "    n_images=100,\n",
    "    samples_per_image=10,\n",
    "    window_size=64,\n",
    "    margin=16,\n",
    "    disp_range=(-16, 16)\n",
    ")\n",
    "\n",
    "# Primer: ocena tvojega nevronskega modela (classifier ali regressor)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "model_type = 'regressor'  # ali 'regressor'\n",
    "neg = False  # ƒçe tvoj regressor v treningu uƒçi negativne pomike, nastavi True\n",
    "model_results = eval_model_on_testset(\n",
    "    model,\n",
    "    test_samples,\n",
    "    device,\n",
    "    model_type=model_type,\n",
    "    negate_pred=neg,\n",
    "    soft_decode=True\n",
    ")\n",
    "\n",
    "# Primer: ocena klasiƒçnega pristopa\n",
    "classical_results = eval_classical_on_testset(\n",
    "    test_samples,\n",
    "    fallback_identity=True,\n",
    "    use_256_for_classical=True\n",
    ")\n",
    "\n",
    "# Primer: primerjava in ploti\n",
    "summary = summarize_and_plot(\n",
    "    [model_results, classical_results],\n",
    "    labels=[model.__class__.__name__, 'Classical_OpenCV'],\n",
    "    outdir='eval_results',\n",
    "    save_plots=False,\n",
    ")\n"
   ],
   "id": "77461a60cb155eba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
