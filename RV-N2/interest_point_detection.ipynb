{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:25:12.393488Z",
     "start_time": "2025-12-07T16:24:54.063608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "from Models import KeypointNet, KeypointDataset\n",
    "from Helper import save_checkpoint_generic, load_checkpoint_generic\n"
   ],
   "id": "cfa9f4796db9bbc2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:25:12.587427Z",
     "start_time": "2025-12-07T16:25:12.420509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# HYPERPARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "# Model parameters (SuperPoint: Adam, lr=0.001, beta=(0.9, 0.999))\n",
    "learning_rate = 0.001\n",
    "adam_betas = (0.9, 0.999)\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Training parameters (iteration-based)\n",
    "num_iterations = 200_000  # SuperPoint uses 200k iterations\n",
    "batch_size = 32  # SuperPoint uses 32\n",
    "\n",
    "# Image parameters\n",
    "image_size = (240, 320)  # (Height, Width)\n",
    "\n",
    "# Dataset parameters\n",
    "num_train_samples = 5000  # Number of pregenerated training samples\n",
    "num_test_samples = 500   # Number of pregenerated test samples\n",
    "\n",
    "# Augmentation settings (applied during training, not during generation)\n",
    "use_homography_augment = True    # Apply random homography to training data\n",
    "use_photometric_augment = True   # Apply brightness/contrast to training data\n",
    "use_geometric_augment = True     # Apply flips to training data\n",
    "\n",
    "# Dataset file paths (.npz format - contains pregenerated images)\n",
    "dataset_cache_dir = './datasets'\n",
    "load_datasets_if_exist = True    # Load from .npz files if available\n",
    "\n",
    "# Checkpoint parameters\n",
    "checkpoint_dir = './checkpoints'\n",
    "save_checkpoint_every = 5000  # Save every N iterations\n",
    "max_checkpoints = 4\n",
    "\n",
    "# Logging parameters\n",
    "eval_every = 100   # Evaluate on test set every N iterations\n",
    "print_every = 10\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(dataset_cache_dir, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Configuration loaded\")\n",
    "print(f\"  Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"  Training samples: {num_train_samples}\")\n",
    "print(f\"  Test samples: {num_test_samples}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Target iterations: {num_iterations:,}\")\n",
    "print(f\"  Training augmentation: {'ENABLED' if use_homography_augment else 'DISABLED'}\")\n",
    "print()\n"
   ],
   "id": "ed395d636eee7e2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "  Device: CUDA\n",
      "  Training samples: 5000\n",
      "  Test samples: 500\n",
      "  Batch size: 32\n",
      "  Target iterations: 200,000\n",
      "  Training augmentation: ENABLED\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:25:12.679862Z",
     "start_time": "2025-12-07T16:25:12.656471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # ============================================================\n",
    "# # DATASET GENERATION AND SAVING (Run once to create datasets)\n",
    "# # ============================================================\n",
    "#\n",
    "# train_samples_path = os.path.join(dataset_cache_dir, f'train_samples_{num_train_samples}.npz')\n",
    "# test_samples_path = os.path.join(dataset_cache_dir, f'test_samples_{num_test_samples}.npz')\n",
    "#\n",
    "# print(\"=\" * 60)\n",
    "# print(\"DATASET GENERATION\")\n",
    "# print(\"=\" * 60)\n",
    "# print()\n",
    "#\n",
    "# # Generate and save training samples (raw, no augmentation)\n",
    "# print(f\"Generating {num_train_samples} training samples...\")\n",
    "# train_generator = KeypointDataset(\n",
    "#     num_samples=num_train_samples,\n",
    "#     image_shape=image_size,\n",
    "#     generate_fn=generate_synthetic_image,\n",
    "#     generate_kwargs={\n",
    "#         'width': image_size[1],\n",
    "#         'height': image_size[0],\n",
    "#         'shape_type': 'random',\n",
    "#     },\n",
    "#     use_homography_augment=False,  # No augmentation during generation\n",
    "#     use_photometric_augment=False,\n",
    "#     use_geometric_augment=False,\n",
    "#     pregenerate=True\n",
    "# )\n",
    "# print(f\"‚úì Training samples generated: {len(train_generator)} samples\")\n",
    "#\n",
    "# # Save training samples\n",
    "# print(f\"Saving to {train_samples_path}...\")\n",
    "# train_generator.save_to_file(train_samples_path)\n",
    "# print(f\"‚úì Training samples saved!\")\n",
    "# print()\n",
    "#\n",
    "# # Generate and save test samples (raw, no augmentation)\n",
    "# print(f\"Generating {num_test_samples} test samples...\")\n",
    "# test_generator = KeypointDataset(\n",
    "#     num_samples=num_test_samples,\n",
    "#     image_shape=image_size,\n",
    "#     generate_fn=generate_synthetic_image,\n",
    "#     generate_kwargs={\n",
    "#         'width': image_size[1],\n",
    "#         'height': image_size[0],\n",
    "#         'shape_type': 'random',\n",
    "#     },\n",
    "#     use_homography_augment=False,  # No augmentation during generation\n",
    "#     use_photometric_augment=False,\n",
    "#     use_geometric_augment=False,\n",
    "#     pregenerate=True\n",
    "# )\n",
    "# print(f\"‚úì Test samples generated: {len(test_generator)} samples\")\n",
    "#\n",
    "# # Save test samples\n",
    "# print(f\"Saving to {test_samples_path}...\")\n",
    "# test_generator.save_to_file(test_samples_path)\n",
    "# print(f\"‚úì Test samples saved!\")\n",
    "# print()\n",
    "#\n",
    "# print(\"=\" * 60)\n",
    "# print(\"‚úì Dataset generation complete!\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"Training samples: {train_samples_path}\")\n",
    "# print(f\"Test samples: {test_samples_path}\")\n",
    "# print()\n"
   ],
   "id": "db4c52bcd31f3516",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:25:25.184656Z",
     "start_time": "2025-12-07T16:25:12.734894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# LOAD DATASETS AND INIT MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATASETS FROM .NPZ FILES\n",
    "# ============================================================\n",
    "\n",
    "train_samples_path = os.path.join(dataset_cache_dir, f'train_samples_{num_train_samples}.npz')\n",
    "test_samples_path = os.path.join(dataset_cache_dir, f'test_samples_{num_test_samples}.npz')\n",
    "\n",
    "train_dataset = None\n",
    "test_dataset = None\n",
    "\n",
    "# Load training dataset WITH augmentation\n",
    "if load_datasets_if_exist and os.path.exists(train_samples_path):\n",
    "    print(f\"Loading training samples from {train_samples_path}...\")\n",
    "    print(f\"  Augmentation: {'ENABLED' if use_homography_augment else 'DISABLED'}\")\n",
    "    try:\n",
    "        train_dataset = KeypointDataset(\n",
    "            num_samples=num_train_samples,\n",
    "            image_shape=image_size,\n",
    "            use_homography_augment=use_homography_augment,\n",
    "            use_photometric_augment=use_photometric_augment,\n",
    "            use_geometric_augment=use_geometric_augment,\n",
    "            pregenerate=False,  # Don't regenerate, just load\n",
    "            load_from_file=train_samples_path\n",
    "        )\n",
    "        print(f\"‚úì Training dataset loaded: {len(train_dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to load training dataset: {e}\")\n",
    "        print(\"Please run the dataset generation cell first!\")\n",
    "        train_dataset = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Training samples not found at {train_samples_path}\")\n",
    "    print(\"Please run the dataset generation cell first!\")\n",
    "\n",
    "# Load test dataset WITHOUT augmentation\n",
    "if load_datasets_if_exist and os.path.exists(test_samples_path):\n",
    "    print(f\"Loading test samples from {test_samples_path}...\")\n",
    "    print(f\"  Augmentation: DISABLED (test set)\")\n",
    "    try:\n",
    "        test_dataset = KeypointDataset(\n",
    "            num_samples=num_test_samples,\n",
    "            image_shape=image_size,\n",
    "            use_homography_augment=False,  # No augmentation for test\n",
    "            use_photometric_augment=False,\n",
    "            use_geometric_augment=False,\n",
    "            pregenerate=False,  # Don't regenerate, just load\n",
    "            load_from_file=test_samples_path\n",
    "        )\n",
    "        print(f\"‚úì Test dataset loaded: {len(test_dataset)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Failed to load test dataset: {e}\")\n",
    "        print(\"Please run the dataset generation cell first!\")\n",
    "        test_dataset = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Test samples not found at {test_samples_path}\")\n",
    "    print(\"Please run the dataset generation cell first!\")\n",
    "\n",
    "# Check if datasets were loaded successfully\n",
    "if train_dataset is None or test_dataset is None:\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚ö†Ô∏è  ERROR: Datasets not loaded!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Please run Cell 3 (Dataset Generation) first to create the .npz files.\")\n",
    "    print()\n",
    "    raise RuntimeError(\"Datasets not found. Run dataset generation cell first.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# CREATE DATALOADERS\n",
    "# ============================================================\n",
    "\n",
    "print(\"Creating DataLoaders...\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"‚úì DataLoaders created\")\n",
    "print(f\"  Training batches per epoch: {len(train_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# MODEL INITIALIZATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"Initializing model...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = KeypointNet().to(device)\n",
    "\n",
    "# Optimizer (SuperPoint paper: Adam with lr=0.001, betas=(0.9, 0.999))\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=adam_betas,\n",
    "    weight_decay=weight_decay\n",
    ")\n"
   ],
   "id": "5ff1a7b425389884",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING SETUP\n",
      "============================================================\n",
      "\n",
      "Loading training samples from ./datasets\\train_samples_5000.npz...\n",
      "  Augmentation: ENABLED\n",
      "Loading 5000 samples from ./datasets\\train_samples_5000.npz...\n",
      "‚úì Loaded 5000 samples!\n",
      "‚úì Training dataset loaded: 5000 samples\n",
      "Loading test samples from ./datasets\\test_samples_500.npz...\n",
      "  Augmentation: DISABLED (test set)\n",
      "Loading 500 samples from ./datasets\\test_samples_500.npz...\n",
      "‚úì Loaded 500 samples!\n",
      "‚úì Test dataset loaded: 500 samples\n",
      "\n",
      "Creating DataLoaders...\n",
      "‚úì DataLoaders created\n",
      "  Training batches per epoch: 157\n",
      "  Test batches: 16\n",
      "\n",
      "Initializing model...\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T16:32:50.165808Z",
     "start_time": "2025-12-07T16:29:37.285554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "# Loss tracking\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "start_iteration = 0\n",
    "\n",
    "# Load checkpoint if exists\n",
    "checkpoint = load_checkpoint_generic(checkpoint_dir, device)\n",
    "if checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_iteration = checkpoint.get('iteration', 0)\n",
    "    train_losses = checkpoint.get('train_losses', [])\n",
    "    test_losses = checkpoint.get('test_losses', [])\n",
    "    print(f\"‚úì Resuming from iteration {start_iteration:,}\")\n",
    "else:\n",
    "    print(\"‚úì Starting from scratch\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ITERATION-BASED TRAINING LOOP\n",
    "# ============================================================\n",
    "\n",
    "model.train()\n",
    "running_loss = 0.0\n",
    "iteration = start_iteration\n",
    "\n",
    "# Create iterator for infinite cycling through dataset\n",
    "train_iterator = cycle(train_loader)\n",
    "\n",
    "while iteration < num_iterations:\n",
    "    # Get next batch (infinite cycling)\n",
    "    images, targets = next(train_iterator)\n",
    "\n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(images, return_logits=True)  # (B, 65, H/8, W/8)\n",
    "    targets_idx = targets.argmax(dim=1)  # (B, H/8, W/8)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = F.cross_entropy(logits, targets_idx)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress\n",
    "    iteration += 1\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # Print training loss\n",
    "    if iteration % print_every == 0:\n",
    "        avg_loss = running_loss / print_every\n",
    "        running_loss = 0.0\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f\"Iter [{iteration:>6}/{num_iterations}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    if iteration % eval_every == 0:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        num_test_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_images, test_targets in test_loader:\n",
    "                test_images = test_images.to(device)\n",
    "                test_targets = test_targets.to(device)\n",
    "\n",
    "                logits = model(test_images, return_logits=True)\n",
    "                targets_idx = test_targets.argmax(dim=1)\n",
    "                loss = F.cross_entropy(logits, targets_idx)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                num_test_batches += 1\n",
    "\n",
    "        avg_test_loss = test_loss / num_test_batches\n",
    "        test_losses.append(avg_test_loss)\n",
    "        print(f\"  ‚îî‚îÄ Test Loss: {avg_test_loss:.4f}\")\n",
    "        model.train()\n",
    "\n",
    "    # Save checkpoint\n",
    "    if iteration % save_checkpoint_every == 0 or iteration == num_iterations:\n",
    "        save_checkpoint_generic(\n",
    "            checkpoint_dir,\n",
    "            iteration,\n",
    "            {\n",
    "                'iteration': iteration,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'config': {\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_iterations': num_iterations,\n",
    "                }\n",
    "            },\n",
    "            max_checkpoints=max_checkpoints\n",
    "        )\n",
    "        print(f\"  ‚îî‚îÄ Checkpoint saved\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úì TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "if len(train_losses) > 0:\n",
    "    print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "if len(test_losses) > 0:\n",
    "    print(f\"Final Test Loss: {test_losses[-1]:.4f}\")\n",
    "print()\n"
   ],
   "id": "5c963dabbb8a6d57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ No checkpoint found, starting from scratch\n",
      "‚úì Starting from scratch\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Iter [     1/200000] Loss: 0.2601\n",
      "Iter [     2/200000] Loss: 0.2044\n",
      "Iter [     3/200000] Loss: 0.1991\n",
      "Iter [     4/200000] Loss: 0.1956\n",
      "Iter [     5/200000] Loss: 0.1851\n",
      "Iter [     6/200000] Loss: 0.1514\n",
      "Iter [     7/200000] Loss: 0.1406\n",
      "Iter [     8/200000] Loss: 0.1372\n",
      "Iter [     9/200000] Loss: 0.1034\n",
      "Iter [    10/200000] Loss: 0.1118\n",
      "Iter [    11/200000] Loss: 0.1196\n",
      "Iter [    12/200000] Loss: 0.1051\n",
      "Iter [    13/200000] Loss: 0.0812\n",
      "Iter [    14/200000] Loss: 0.0825\n",
      "Iter [    15/200000] Loss: 0.0806\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 41\u001B[39m\n\u001B[32m     37\u001B[39m train_iterator = cycle(train_loader)\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m iteration < num_iterations:\n\u001B[32m     40\u001B[39m     \u001B[38;5;66;03m# Get next batch (infinite cycling)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     images, targets = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m     images = images.to(device)\n\u001B[32m     44\u001B[39m     targets = targets.to(device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    729\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    730\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    731\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    733\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    735\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    736\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    738\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    786\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    787\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m788\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    790\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N2\\Models.py:534\u001B[39m, in \u001B[36mKeypointDataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m    531\u001B[39m \u001B[38;5;66;03m# Apply augmentations in order:\u001B[39;00m\n\u001B[32m    532\u001B[39m \u001B[38;5;66;03m# 1. Homography (perspective transformation)\u001B[39;00m\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_homography_augment:\n\u001B[32m--> \u001B[39m\u001B[32m534\u001B[39m     img_gray, keypoints = \u001B[43mapply_homography_augmentation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[43m        \u001B[49m\u001B[43mimg_gray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeypoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mimage_shape\u001B[49m\n\u001B[32m    536\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[38;5;66;03m# 2. Photometric (brightness, contrast)\u001B[39;00m\n\u001B[32m    539\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_photometric_augment:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N2\\Models.py:322\u001B[39m, in \u001B[36mapply_homography_augmentation\u001B[39m\u001B[34m(img, keypoints, image_shape, max_retries)\u001B[39m\n\u001B[32m    319\u001B[39m homography_matrix = generate_random_homography(W, H)\n\u001B[32m    321\u001B[39m \u001B[38;5;66;03m# Apply to image and keypoints\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m img_warped, keypoints_warped = \u001B[43mapply_homography\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeypoints\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhomography_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[38;5;66;03m# Accept if we retained enough keypoints\u001B[39;00m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(keypoints_warped) >= min_keypoints:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RV\\Racunalniski Vid\\RV-N2\\Generator.py:511\u001B[39m, in \u001B[36mapply_homography\u001B[39m\u001B[34m(img, keypoints, H, width, height)\u001B[39m\n\u001B[32m    509\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Apply homography to image and keypoints.\"\"\"\u001B[39;00m\n\u001B[32m    510\u001B[39m \u001B[38;5;66;03m# Transform image\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m511\u001B[39m img_warped = \u001B[43mcv2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwarpPerspective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    513\u001B[39m \u001B[38;5;66;03m# Transform keypoints\u001B[39;00m\n\u001B[32m    514\u001B[39m keypoints_homogeneous = np.hstack([keypoints, np.ones((\u001B[38;5;28mlen\u001B[39m(keypoints), \u001B[32m1\u001B[39m))])\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# PLOT TRAINING CURVES\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "if len(train_losses) == 0 and len(test_losses) == 0:\n",
    "    print(\"‚ö†Ô∏è  No training data to plot. Run the training loop first.\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "    # Plot training losses\n",
    "    if len(train_losses) > 0:\n",
    "        iterations_range = [(i + 1) for i in range(len(train_losses))]\n",
    "        ax.plot(iterations_range, train_losses, 'b-', label='Training Loss', linewidth=2, alpha=0.7)\n",
    "        print(f\"‚úì Training losses plotted ({len(train_losses)} points)\")\n",
    "\n",
    "    # Plot test losses\n",
    "    if len(test_losses) > 0:\n",
    "        test_iterations_range = [(i + 1) * eval_every for i in range(len(test_losses))]\n",
    "        ax.plot(test_iterations_range, test_losses, 'r-', label='Test Loss', linewidth=2, alpha=0.7)\n",
    "        print(f\"‚úì Test losses plotted ({len(test_losses)} points)\")\n",
    "\n",
    "    ax.set_xlabel('Iteration', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('Training Progress - Interest Point Detection', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add minor gridlines for better readability\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(which='minor', alpha=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    if len(train_losses) > 0:\n",
    "        print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "        print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "    if len(test_losses) > 0:\n",
    "        print(f\"Final Test Loss: {test_losses[-1]:.4f}\")\n",
    "        print(f\"Best Test Loss: {min(test_losses):.4f}\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n"
   ],
   "id": "65bb98e5b93c7f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================\n",
    "# MODEL TESTING - Load Checkpoint and Evaluate\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL TESTING\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Test configuration\n",
    "test_checkpoint_dir = './checkpoints'  # Path to checkpoint directory\n",
    "num_test_visualizations = 6  # Number of samples to visualize\n",
    "\n",
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KeypointNet().to(device)\n",
    "\n",
    "# Load latest checkpoint\n",
    "checkpoint = load_checkpoint_generic(test_checkpoint_dir, device)\n",
    "if checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    iteration = checkpoint.get('iteration', 'unknown')\n",
    "    print(f\"‚úì Loaded checkpoint from iteration {iteration:,}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No checkpoint found! Using untrained model.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load test dataset if not already loaded\n",
    "if 'test_dataset' not in locals() or test_dataset is None:\n",
    "    test_samples_path = os.path.join(dataset_cache_dir, f'test_samples_{num_test_samples}.npz')\n",
    "    test_dataset = KeypointDataset(\n",
    "        num_samples=num_test_samples,\n",
    "        image_shape=image_size,\n",
    "        use_homography_augment=False,\n",
    "        use_photometric_augment=False,\n",
    "        use_geometric_augment=False,\n",
    "        pregenerate=False,\n",
    "        load_from_file=test_samples_path\n",
    "    )\n",
    "    print(f\"‚úì Test dataset loaded: {len(test_dataset)} samples\")\n",
    "\n",
    "# Evaluate on full test set\n",
    "print(\"Evaluating on test set...\")\n",
    "total_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(images, return_logits=True)\n",
    "        targets_idx = targets.argmax(dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets_idx)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "avg_test_loss = total_loss / len(test_loader)\n",
    "print(f\"‚úì Test Loss: {avg_test_loss:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualize predictions\n",
    "print(f\"Visualizing {num_test_visualizations} predictions...\")\n",
    "test_indices = np.random.choice(len(test_dataset), num_test_visualizations, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(num_test_visualizations, 3, figsize=(15, 5 * num_test_visualizations))\n",
    "if num_test_visualizations == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for plot_idx, dataset_idx in enumerate(test_indices):\n",
    "        image, target = test_dataset[dataset_idx]\n",
    "\n",
    "        # Get prediction\n",
    "        image_batch = image.unsqueeze(0).to(device)\n",
    "        logits = model(image_batch, return_logits=True)\n",
    "        heatmap = model(image_batch, return_logits=False)\n",
    "\n",
    "        # Extract keypoints from target and prediction\n",
    "        from Models import extract_keypoints_from_target, process_output_torch\n",
    "\n",
    "        target_kpts = extract_keypoints_from_target(target)\n",
    "        _, pred_kpts_list = process_output_torch(logits, threshold=0.015)\n",
    "        pred_kpts = pred_kpts_list[0]\n",
    "\n",
    "        # Convert tensors to numpy for visualization\n",
    "        img_np = image.squeeze().cpu().numpy()\n",
    "        heatmap_np = heatmap.squeeze().cpu().numpy()\n",
    "\n",
    "        # Plot input image with ground truth\n",
    "        axes[plot_idx, 0].imshow(img_np, cmap='gray')\n",
    "        if len(target_kpts) > 0:\n",
    "            axes[plot_idx, 0].scatter(target_kpts[:, 0], target_kpts[:, 1],\n",
    "                                     c='lime', s=50, marker='x', linewidths=2)\n",
    "        axes[plot_idx, 0].set_title(f'Input + Ground Truth ({len(target_kpts)} points)')\n",
    "        axes[plot_idx, 0].axis('off')\n",
    "\n",
    "        # Plot heatmap\n",
    "        axes[plot_idx, 1].imshow(img_np, cmap='gray')\n",
    "        axes[plot_idx, 1].imshow(heatmap_np, cmap='jet', alpha=0.5)\n",
    "        axes[plot_idx, 1].set_title('Prediction Heatmap')\n",
    "        axes[plot_idx, 1].axis('off')\n",
    "\n",
    "        # Plot detected keypoints\n",
    "        axes[plot_idx, 2].imshow(img_np, cmap='gray')\n",
    "        if len(pred_kpts) > 0:\n",
    "            axes[plot_idx, 2].scatter(pred_kpts[:, 0], pred_kpts[:, 1],\n",
    "                                     c='red', s=50, marker='+', linewidths=2)\n",
    "        axes[plot_idx, 2].set_title(f'Detected Keypoints ({len(pred_kpts)} points)')\n",
    "        axes[plot_idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úì Testing complete!\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "403f75d0b1638e8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
